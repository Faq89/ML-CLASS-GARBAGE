# -*- coding: utf-8 -*-
"""Reciclaj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gMb99-5Q2iKAIwr5-WynBOVvgDH-bEnJ
"""

!pip install torch torchvision

from google.colab import files

# Subir archivo
uploaded = files.upload()

# Descomprimir archivo
!unzip /content/archive.zip -d /content/dataset

import os
import shutil

# Rutas
base_dir = '/content/dataset/Garbage classification/Garbage classification'
organized_dir = '/content/organized_dataset'

# Crear carpetas organizadas
os.makedirs(organized_dir, exist_ok=True)
os.makedirs(f'{organized_dir}/train', exist_ok=True)
os.makedirs(f'{organized_dir}/val', exist_ok=True)
os.makedirs(f'{organized_dir}/test', exist_ok=True)

# Configurar proporciones
train_split = 0.7
val_split = 0.15
test_split = 0.15

# Mover archivos a carpetas organizadas
for class_name in os.listdir(base_dir):
    class_path = os.path.join(base_dir, class_name)
    if not os.path.isdir(class_path):
        continue

    # Crear carpetas por clase
    os.makedirs(f'{organized_dir}/train/{class_name}', exist_ok=True)
    os.makedirs(f'{organized_dir}/val/{class_name}', exist_ok=True)
    os.makedirs(f'{organized_dir}/test/{class_name}', exist_ok=True)

    # Listar imágenes
    images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]
    total_images = len(images)
    train_count = int(total_images * train_split)
    val_count = int(total_images * val_split)

    # Dividir en train, val, test
    for i, image in enumerate(images):
        src = os.path.join(class_path, image)
        if i < train_count:
            dst = f'{organized_dir}/train/{class_name}/{image}'
        elif i < train_count + val_count:
            dst = f'{organized_dir}/val/{class_name}/{image}'
        else:
            dst = f'{organized_dir}/test/{class_name}/{image}'
        shutil.copy(src, dst)

print("Dataset organizado en:", organized_dir)

# Función para eliminar la clase "trash" ya que tiene resultados desfavorables (0.20 Loss)
def eliminar_clase_trash(organized_dir):
    for split in ['train', 'val', 'test']:
        for class_name in os.listdir(f'{organized_dir}/{split}'):
            if class_name == 'trash':
                trash_dir = os.path.join(organized_dir, split, 'trash')
                for image in os.listdir(trash_dir):
                    os.remove(os.path.join(trash_dir, image))
                os.rmdir(trash_dir)
                print(f"Clase 'trash' eliminada de {split}")

eliminar_clase_trash(organized_dir)

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Transformaciones
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Cargar datasets
train_dataset = datasets.ImageFolder(root='/content/organized_dataset/train', transform=transform)
val_dataset = datasets.ImageFolder(root='/content/organized_dataset/val', transform=transform)
test_dataset = datasets.ImageFolder(root='/content/organized_dataset/test', transform=transform)

# Crear DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Verificar las clases
print("Clases:", train_dataset.classes)
print(f"Imágenes: {len(train_dataset)} entrenamiento, {len(val_dataset)} validación, {len(test_dataset)} prueba.")

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torchvision.models import ResNet18_Weights

# Cargar el modelo preentrenado con el nuevo argumento 'weights'
model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)  # Cargar ResNet18
num_features = model.fc.in_features       # Extraer el número de entradas de la capa fully connected
model.fc = nn.Linear(num_features, 5)     # Reemplazarla con una capa que tenga 5 salidas (clases), excluyendo 'trash'

# Configurar el dispositivo
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# Definir la pérdida y el optimizador
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.8)

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Cargar el modelo preentrenado (ResNet18) y ajustar la capa final
model = models.resnet18(pretrained=True)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 5)  # Reemplazarla con una capa que tenga 5 salidas (clases)

# Configurar el dispositivo
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# Definir la pérdida y el optimizador /
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.08)

# Definir las transformaciones de los datos
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Cargar los datasets
train_dataset = datasets.ImageFolder(root='/content/organized_dataset/train', transform=transform)
val_dataset = datasets.ImageFolder(root='/content/organized_dataset/val', transform=transform)
test_dataset = datasets.ImageFolder(root='/content/organized_dataset/test', transform=transform)

# Crear DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Verificar las clases
print("Clases:", train_dataset.classes)
print(f"Imágenes: {len(train_dataset)} entrenamiento, {len(val_dataset)} validación, {len(test_dataset)} prueba.")

# Entrenamientooo del modelo
epochs = 20
train_losses = []
train_accuracies = []

for epoch in range(epochs):
    model.train()  # Establecemos modo entrenamiento
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # Limpiar los gradientes
        outputs = model(images)  # Obtener las predicciones
        loss = criterion(outputs, labels)  # Calcular la pérdida
        loss.backward()  # Retropropagación de los gradientes
        optimizer.step()  # Actualización de los pesos

        running_loss += loss.item()

        # Calcular precisión
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    # Calcular precisión de la época
    accuracy = 100 * correct / total  #
    train_losses.append(running_loss / len(train_loader))
    train_accuracies.append(accuracy)


    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')


plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Entrenamiento')
plt.xlabel('Época')
plt.ylabel('Pérdida')
plt.title('Pérdida durante el entrenamiento')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Entrenamiento')
plt.xlabel('Época')
plt.ylabel('Precisión (%)')
plt.title('Precisión durante el entrenamiento')
plt.legend()

plt.show()

from sklearn.metrics import classification_report

# Reporte de clasificacion

def evaluate_model(model, dataloader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    return all_labels, all_preds

# Evaluar en validación
val_labels, val_preds = evaluate_model(model, val_loader)
print("Reporte de clasificación (Validación):")
print(classification_report(val_labels, val_preds, target_names=train_dataset.classes))

torch.save(model.state_dict(), 'modelo_entrenado.pt') #Guarda el modelo

import torch
from PIL import Image
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from google.colab import files
from torchvision import models

# Defino las clases manualmente
clases = ['Carton', 'Vidrio', 'Metal', 'Papel', 'Plastico']

# Cargar el modelo ResNet18 previamente entrenado
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = models.resnet18(pretrained=True)
num_features = model.fc.in_features
model.fc = torch.nn.Linear(num_features, 5)  # Número de clases del modelo
model.load_state_dict(torch.load('modelo_entrenado.pt'))  # Carg los pesos del modelo cargado
model = model.to(device)

# Transformación ya usada
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Función para predecir una imagen
def predecir_imagen(imagen_path, model):
    # Cargar la imagen
    image = Image.open(imagen_path)

    # Aplicar las transformaciones
    image = transform(image).unsqueeze(0)

    # Mover la imagen al dispositivo (todevice=)
    image = image.to(device)

    # Hacer la predicción
    model.eval()  # Establecer el modelo en modo evaluación
    with torch.no_grad():  # No necesitamos calcular los gradientes
        outputs = model(image)  # Obtener las predicciones
        _, predicted_class = torch.max(outputs, 1)  # Obtener la clase predicha

    return predicted_class.item()  # Devolver la clase predicha

# Subir la imagen
uploaded = files.upload()

# Obtener el nombre del archivo cargado
imagen_path = next(iter(uploaded))  # Obtener el nombre del archivo cargado

# Realizar la predicción
prediccion = predecir_imagen(imagen_path, model)

# Mostrar la imagen
image = Image.open(imagen_path)
plt.imshow(image)
plt.axis('off')  # no mostrar ejes
plt.show()

# Mostrar la clase predicha
print(f'Predicción: {clases[prediccion]}')